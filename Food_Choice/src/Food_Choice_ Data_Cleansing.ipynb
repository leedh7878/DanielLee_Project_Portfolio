{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning & EDA Practice** \n",
    "by Daniel Lee"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose is to clean the data, not to make statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in csvfile. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Description**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"../data/Food_choices/food_coded.csv\"\n",
    "data_ori = pd.read_csv(csv_file_path, low_memory=False)\n",
    "data_cleaning = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# info function: including the index dtype and columns, non-null values and memory usage.\n",
    "data_cleaning.info()\n",
    "# data_cleaning.drop_duplicates() # check duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Numeric columns:\n",
      "GPA\n",
      "comfort_food\n",
      "comfort_food_reasons\n",
      "diet_current\n",
      "eating_changes\n",
      "father_profession\n",
      "fav_cuisine\n",
      "food_childhood\n",
      "healthy_meal\n",
      "ideal_diet\n",
      "meals_dinner_friend\n",
      "mother_profession\n",
      "type_sports\n",
      "weight\n",
      "\n",
      "Numeric columns:\n",
      "Gender\n",
      "breakfast\n",
      "calories_chicken\n",
      "calories_day\n",
      "calories_scone\n",
      "coffee\n",
      "comfort_food_reasons_coded\n",
      "cook\n",
      "comfort_food_reasons_coded.1\n",
      "cuisine\n",
      "diet_current_coded\n",
      "drink\n",
      "eating_changes_coded\n",
      "eating_changes_coded1\n",
      "eating_out\n",
      "employment\n",
      "ethnic_food\n",
      "exercise\n",
      "father_education\n",
      "fav_cuisine_coded\n",
      "fav_food\n",
      "fries\n",
      "fruit_day\n",
      "grade_level\n",
      "greek_food\n",
      "healthy_feeling\n",
      "ideal_diet_coded\n",
      "income\n",
      "indian_food\n",
      "italian_food\n",
      "life_rewarding\n",
      "marital_status\n",
      "mother_education\n",
      "nutritional_check\n",
      "on_off_campus\n",
      "parents_cook\n",
      "pay_meal_out\n",
      "persian_food\n",
      "self_perception_weight\n",
      "soup\n",
      "sports\n",
      "thai_food\n",
      "tortilla_calories\n",
      "turkey_calories\n",
      "veggies_day\n",
      "vitamins\n",
      "waffle_calories\n"
     ]
    }
   ],
   "source": [
    "# pandas.Dataframe.select_dtypes() function: Return a subset of the DataFrame’s columns based on the column dtypes.\n",
    "\n",
    "obj_df = data_cleaning.select_dtypes(include=['object'])\n",
    "num_df = data_cleaning.select_dtypes(exclude=['object'])\n",
    "\n",
    "#helpfunction to seperate categorical and numerical features\n",
    "def printColumnTypes(non_numeric_df, numeric_df):\n",
    "    '''separates non-numeric and numeric columns'''\n",
    "    print(\"Non-Numeric columns:\")\n",
    "    for col in non_numeric_df:\n",
    "        print(f\"{col}\")\n",
    "    print(\"\")\n",
    "    print(\"Numeric columns:\")\n",
    "    for col in numeric_df:\n",
    "        print(f\"{col}\")\n",
    "\n",
    "printColumnTypes(obj_df, num_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few problems for missing data method\n",
    "\n",
    "* For example, by dropping rows/columns, you’re essentially losing information that might be useful for prediction\n",
    "\n",
    "* On the other hand, imputing values will introduce bias to your data but it still might better than removing your features.\n",
    "\n",
    "Here is a great analogy for this dilemma in this article by Elite Data Science.\n",
    "\n",
    "Missing data is like missing a puzzle piece. If you drop it, that’s like pretending the puzzle slot isn’t there. If you impute it, that’s like trying to squeeze in a piece from somewhere else in the puzzle.\n",
    "\n",
    "source:https://medium.com/bitgrit-data-science-publication/data-cleaning-with-python-f6bc3da64e45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA                  2\n",
      "Gender               0\n",
      "breakfast            0\n",
      "calories_chicken     0\n",
      "calories_day        19\n",
      "                    ..\n",
      "type_sports         26\n",
      "veggies_day          0\n",
      "vitamins             0\n",
      "waffle_calories      0\n",
      "weight               2\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_per_column = data_cleaning.isnull().sum()\n",
    "# .sum() funciton return series(dataframe with one column; have different parameter from dataframe)\n",
    "\n",
    "print(missing_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shape function give give dimension of the dataframe which is [x,y]. length:x -> index = 0, width:y -> index = 1\n",
    "Thus, we can use that info to find number of data and attributes.\n",
    "'''\n",
    "num_obs = np.product(data_ori.shape[0])\n",
    "num_attr = np.product(data_ori.shape[1])\n",
    "# This approach may not needed if we use info() instead but, who know? there might be an update in data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droping Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Threshold for drop attributes would be 30% for big data and 20% for small data.\n",
    "'''\n",
    "# pandas.DataFrame.drop: Drop specified labels from rows or columns.\n",
    "\n",
    "# pandas.DataFrame.iloc = for index, .loc = for column name\n",
    "missing_percentage = (missing_per_column/num_obs)\n",
    "\n",
    "#lt = less than, gt = greater than, le = less and equal, ge = greater and equal\n",
    "\n",
    "feature_to_drop = missing_percentage[missing_percentage.ge(0.2)]\n",
    "feature_to_keep = missing_percentage[missing_percentage.lt(0.2)]\n",
    "#()parameter: subset of series, []parameter: index of subset\n",
    "\n",
    "feature_to_drop_index = feature_to_drop.index\n",
    "feature_to_keep_index = feature_to_keep.index\n",
    "\n",
    "data_cleaning = data_cleaning[feature_to_keep_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much simpler way to drop column with certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna(thresh): Require that many non-NA values.\n",
    "\n",
    "data_cleaning2 = data_ori.copy()\n",
    "thresh4data = len(data_cleaning2)*0.8\n",
    "data_cleaning2 = data_cleaning2.dropna(axis =1, thresh=thresh4data)\n",
    "# dropna() function returns a new DataFrame with missing values removed and does not modify the original DataFrame in place.\n",
    "data_cleaning2 = data_cleaning2.dropna(axis =0, thresh= data_cleaning2.shape[1]*0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the dtypes function to distinguish between categorical and numerical data, we may find that some features that appear to be numerical are instead assigned to the categorical type.\n",
    "We have observed that the features, GPA and Weight, have the potential to be represented as numerical data. However, the raw data in these features require cleaning to achieve this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>diet_current</th>\n",
       "      <th>eating_changes</th>\n",
       "      <th>father_profession</th>\n",
       "      <th>fav_cuisine</th>\n",
       "      <th>food_childhood</th>\n",
       "      <th>healthy_meal</th>\n",
       "      <th>ideal_diet</th>\n",
       "      <th>meals_dinner_friend</th>\n",
       "      <th>mother_profession</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>eat good and exercise</td>\n",
       "      <td>eat faster</td>\n",
       "      <td>profesor</td>\n",
       "      <td>Arabic cuisine</td>\n",
       "      <td>rice  and chicken</td>\n",
       "      <td>looks not oily</td>\n",
       "      <td>being healthy</td>\n",
       "      <td>rice, chicken,  soup</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>car racing</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>I eat about three times a day with some snacks...</td>\n",
       "      <td>I eat out more than usual.</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>Italian</td>\n",
       "      <td>chicken and biscuits, beef soup, baked beans</td>\n",
       "      <td>Grains, Veggies, (more of grains and veggies),...</td>\n",
       "      <td>Try to eat 5-6 small meals a day. While trying...</td>\n",
       "      <td>Pasta, steak, chicken</td>\n",
       "      <td>Nurse RN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>toast and fruit for breakfast, salad for lunch...</td>\n",
       "      <td>sometimes choosing to eat fast food instead of...</td>\n",
       "      <td>owns business</td>\n",
       "      <td>italian</td>\n",
       "      <td>mac and cheese, pizza, tacos</td>\n",
       "      <td>usually includes natural ingredients; nonproce...</td>\n",
       "      <td>i would say my ideal diet is my current diet</td>\n",
       "      <td>chicken and rice with veggies, pasta, some kin...</td>\n",
       "      <td>owns business</td>\n",
       "      <td>none</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>College diet, cheap and easy foods most nights...</td>\n",
       "      <td>Accepting cheap and premade/store bought foods</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Beef stroganoff, tacos, pizza</td>\n",
       "      <td>Fresh fruits&amp; vegetables, organic meats</td>\n",
       "      <td>Healthy, fresh veggies/fruits &amp; organic foods</td>\n",
       "      <td>Grilled chicken \\rStuffed Shells\\rHomemade Chili</td>\n",
       "      <td>Special Education Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>I try to eat healthy but often struggle becaus...</td>\n",
       "      <td>I have eaten generally the same foods but I do...</td>\n",
       "      <td>IT</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Pasta, chicken tender, pizza</td>\n",
       "      <td>A lean protein such as grilled chicken, green ...</td>\n",
       "      <td>Ideally I would like to be able to eat healthi...</td>\n",
       "      <td>Chicken Parmesan, Pulled Pork, Spaghetti and m...</td>\n",
       "      <td>Substance Abuse Conselor</td>\n",
       "      <td>Softball</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA                      comfort_food        comfort_food_reasons   \n",
       "0    2.4                              none       we dont have comfort   \\\n",
       "1  3.654       chocolate, chips, ice cream        Stress, bored, anger   \n",
       "2    3.3   frozen yogurt, pizza, fast food             stress, sadness   \n",
       "3    3.2  Pizza, Mac and cheese, ice cream                     Boredom   \n",
       "4    3.5      Ice cream, chocolate, chips   Stress, boredom, cravings    \n",
       "\n",
       "                                        diet_current   \n",
       "0                              eat good and exercise  \\\n",
       "1  I eat about three times a day with some snacks...   \n",
       "2  toast and fruit for breakfast, salad for lunch...   \n",
       "3  College diet, cheap and easy foods most nights...   \n",
       "4  I try to eat healthy but often struggle becaus...   \n",
       "\n",
       "                                      eating_changes father_profession   \n",
       "0                                        eat faster          profesor   \\\n",
       "1                        I eat out more than usual.     Self employed    \n",
       "2  sometimes choosing to eat fast food instead of...     owns business   \n",
       "3     Accepting cheap and premade/store bought foods         Mechanic    \n",
       "4  I have eaten generally the same foods but I do...                IT   \n",
       "\n",
       "      fav_cuisine                                food_childhood   \n",
       "0  Arabic cuisine                            rice  and chicken   \\\n",
       "1         Italian  chicken and biscuits, beef soup, baked beans   \n",
       "2         italian                  mac and cheese, pizza, tacos   \n",
       "3        Turkish                  Beef stroganoff, tacos, pizza   \n",
       "4        Italian                  Pasta, chicken tender, pizza    \n",
       "\n",
       "                                        healthy_meal   \n",
       "0                                    looks not oily   \\\n",
       "1  Grains, Veggies, (more of grains and veggies),...   \n",
       "2  usually includes natural ingredients; nonproce...   \n",
       "3           Fresh fruits& vegetables, organic meats    \n",
       "4  A lean protein such as grilled chicken, green ...   \n",
       "\n",
       "                                          ideal_diet   \n",
       "0                                     being healthy   \\\n",
       "1  Try to eat 5-6 small meals a day. While trying...   \n",
       "2       i would say my ideal diet is my current diet   \n",
       "3     Healthy, fresh veggies/fruits & organic foods    \n",
       "4  Ideally I would like to be able to eat healthi...   \n",
       "\n",
       "                                 meals_dinner_friend   \n",
       "0                               rice, chicken,  soup  \\\n",
       "1                             Pasta, steak, chicken    \n",
       "2  chicken and rice with veggies, pasta, some kin...   \n",
       "3   Grilled chicken \\rStuffed Shells\\rHomemade Chili   \n",
       "4  Chicken Parmesan, Pulled Pork, Spaghetti and m...   \n",
       "\n",
       "           mother_profession  type_sports                    weight  \n",
       "0                 unemployed   car racing                       187  \n",
       "1                  Nurse RN   Basketball                        155  \n",
       "2              owns business         none  I'm not answering this.   \n",
       "3  Special Education Teacher          NaN             Not sure, 240  \n",
       "4   Substance Abuse Conselor     Softball                       190  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify non-numerical data in a column, we can look for the unique values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.4' '3.654' '3.3' '3.2' '3.5' '2.25' '3.8' '3.904' '3.4' '3.6' '3.1'\n",
      " nan '4' '2.2' '3.87' '3.7' '3.9' '2.8' '3' '3.65' '3.89' '2.9' '3.605'\n",
      " '3.83' '3.292' '3.35' 'Personal ' '2.6' '3.67' '3.73' '3.79 bitch' '2.71'\n",
      " '3.68' '3.75' '3.92' 'Unknown' '3.77' '3.63' '3.882']\n",
      "['187' '155' \"I'm not answering this. \" 'Not sure, 240' '190' '180' '137'\n",
      " '125' '116' '110' '264' '123' '185' '145' '170' '135' '165' '175' '195'\n",
      " '105' '160' '167' '115' '205' nan '128' '150' '140' '120' '100' '113'\n",
      " '168' '169' '200' '265' '192' '118' '210' '112' '144 lbs' '130' '127'\n",
      " '129' '260' '184' '230' '138' '156']\n"
     ]
    }
   ],
   "source": [
    "print(obj_df['GPA'].unique())\n",
    "print(obj_df['weight'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The drop() method will remove an entire row from a DataFrame when given a single index label, instead of removing a single value from a specific column.\n",
    "\n",
    "# replace with correct format of data\n",
    "data_cleaning['GPA'] = data_cleaning['GPA'].replace('3.79 bitch', 3.79)\n",
    "\n",
    "# convert data into numeric, errors= 'coerce' change non-numeric to nan\n",
    "data_cleaning['GPA'] = pd.to_numeric(data_cleaning['GPA'], errors ='coerce')\n",
    "data_cleaning['weight'] = pd.to_numeric(data_cleaning['weight'],errors='coerce' )\n",
    "\n",
    "obj_df = obj_df.drop(columns=['GPA', 'weight'],axis=1)\n",
    "num_df = data_cleaning.select_dtypes(exclude=['object'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "object: texts, text values, or a mix of numeric and non-numeric values\n",
    "\n",
    "For the column with object datatype can be change to categorical data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       comfort_food        comfort_food_reasons   \n",
      "0                              none       we dont have comfort   \\\n",
      "1       chocolate, chips, ice cream        stress, bored, anger   \n",
      "2   frozen yogurt, pizza, fast food             stress, sadness   \n",
      "3  pizza, mac and cheese, ice cream                     boredom   \n",
      "4      ice cream, chocolate, chips   stress, boredom, cravings    \n",
      "\n",
      "                                        diet_current   \n",
      "0                              eat good and exercise  \\\n",
      "1  i eat about three times a day with some snacks...   \n",
      "2  toast and fruit for breakfast, salad for lunch...   \n",
      "3  college diet, cheap and easy foods most nights...   \n",
      "4  i try to eat healthy but often struggle becaus...   \n",
      "\n",
      "                                      eating_changes father_profession   \n",
      "0                                        eat faster          profesor   \\\n",
      "1                        i eat out more than usual.     self employed    \n",
      "2  sometimes choosing to eat fast food instead of...     owns business   \n",
      "3     accepting cheap and premade/store bought foods         mechanic    \n",
      "4  i have eaten generally the same foods but i do...                it   \n",
      "\n",
      "      fav_cuisine                                food_childhood   \n",
      "0  arabic cuisine                            rice  and chicken   \\\n",
      "1         italian  chicken and biscuits, beef soup, baked beans   \n",
      "2         italian                  mac and cheese, pizza, tacos   \n",
      "3        turkish                  beef stroganoff, tacos, pizza   \n",
      "4        italian                  pasta, chicken tender, pizza    \n",
      "\n",
      "                                        healthy_meal   \n",
      "0                                    looks not oily   \\\n",
      "1  grains, veggies, (more of grains and veggies),...   \n",
      "2  usually includes natural ingredients; nonproce...   \n",
      "3           fresh fruits& vegetables, organic meats    \n",
      "4  a lean protein such as grilled chicken, green ...   \n",
      "\n",
      "                                          ideal_diet   \n",
      "0                                     being healthy   \\\n",
      "1  try to eat 5-6 small meals a day. while trying...   \n",
      "2       i would say my ideal diet is my current diet   \n",
      "3     healthy, fresh veggies/fruits & organic foods    \n",
      "4  ideally i would like to be able to eat healthi...   \n",
      "\n",
      "                                 meals_dinner_friend   \n",
      "0                               rice, chicken,  soup  \\\n",
      "1                             pasta, steak, chicken    \n",
      "2  chicken and rice with veggies, pasta, some kin...   \n",
      "3   grilled chicken \\rstuffed shells\\rhomemade chili   \n",
      "4  chicken parmesan, pulled pork, spaghetti and m...   \n",
      "\n",
      "           mother_profession  \n",
      "0                 unemployed  \n",
      "1                  nurse rn   \n",
      "2              owns business  \n",
      "3  special education teacher  \n",
      "4   substance abuse conselor  \n"
     ]
    }
   ],
   "source": [
    "obj_columns = data_cleaning.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# use lambda function tp convert it to lowercase and fix grammar \n",
    "data_cleaning[obj_columns] = data_cleaning[obj_columns].apply(lambda x: (x.str.lower()))\n",
    "\n",
    "    \n",
    "print(data_cleaning[obj_columns].head())\n",
    "# print(data_cleaning['fav_cuisine'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the codebook, there are comments that some features are ideal for perform NLP(Nautral Language Processing). Thus, I used 3 features: comfort_food, comfort_food_reasons and diet_current\n",
    "\n",
    "I used NLTK python library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK implementation (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Tools for NLTK package\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'packages to download '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''packages to download '''\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"maxent_ne_chunker\")\n",
    "# nltk.download(\"words\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ars.usda.gov/ARSUserFiles/80400530/pdf/1112/food_category_list.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the data that we are going to apply NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_nlp = data_cleaning[['comfort_food', 'comfort_food_reasons', 'diet_current']]\n",
    "\n",
    "data_nlp= data_nlp.astype(str)\n",
    "\n",
    "data_nlp_prev = data_nlp ## copies of orginal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is main function that chunk the sentence into word with POS tag using parser. It will also create tree that shows structure of sentence'''\n",
    "def chunk_NP(text, origin=True):    \n",
    "    grammar =  r'''\n",
    "    NP: {<FT><NN>|<RB>?<NN.*>+|<NN><CC><NN>|<DT>?<NN|NNS>+<POS>?}\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    The rule states that whenever the chunk finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN) then the Noun Phrase(NP) chunk should be formed.\n",
    "    '''\n",
    "    \n",
    "    if type(text) is not str:\n",
    "        return ['none']\n",
    "    else:    \n",
    "        \n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        lotr_pos_tags = nltk.pos_tag(tokens)\n",
    "        chunk_parser = nltk.RegexpParser(grammar)\n",
    "        tree = chunk_parser.parse(lotr_pos_tags)\n",
    "\n",
    "        noun_phrases = []\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() =='NP':\n",
    "                np_parts = []\n",
    "                for leaf in subtree.leaves():\n",
    "                    np_parts.append(leaf[0])\n",
    "                noun_phrases.append(\" \".join(np_parts))\n",
    "\n",
    "        \n",
    "        return noun_phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tree(text):\n",
    "    grammar =  r'''\n",
    "    NP: {<NN>|<RB>?<NN.*>+|<NN><CC><NN>|<DT>?<NN|NNS>+<POS>?}\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''RB for extract 'and'\n",
    "    '''\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lotr_pos_tags = nltk.pos_tag(tokens)\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "    tree = chunk_parser.parse(lotr_pos_tags)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/', 'almond', 'any kind', 'banana sandwich', 'beef jerky', 'bread', 'bread/crackers', 'broccoli', 'brownie', 'burger', 'burrito', 'butter', 'butter naan', 'cake', 'candy', 'candy bar', 'candy pop chocolate chipotle moe', 'carrot', 'cereal', 'cheese', 'cheeseburger', 'cheesecake', 'cheez-its', 'chex-mix', 'chicken', 'chicken curry', 'chicken finger', 'chicken nugget', 'chicken nuggs', 'chicken wing', 'chilli', 'chip', 'chocolate', 'chocolate bar', 'chocolate brownie', 'chocolate ice cream', 'coffee', 'cookie dough', 'cooky', 'cornbread', 'cottage cheese', 'cup', 'deli sandwhich', 'dessets', 'dip', 'dish', 'donut', 'doritos', 'doughnut', 'egg', 'fast food', 'fire', 'food', 'fritos', 'fruit', 'fruit snack', 'fry', 'grandma', 'grandma homemade chocolate cake anything homemade', 'grape', 'hamburger', 'home', 'ice capps', 'ice crea', 'ice cream', 'ice cream/milkshake', 'ice-cream', 'icecream', 'kit kat', 'lasagna', 'lasagne', 'mac', 'macaroni', 'macaroon', 'mcdonalds', 'meatball sub', 'milkshake', 'mix', 'moes', 'mozzarella stick', 'nan', 'none', 'noodle', 'nugget', 'nutella', 'omelet', 'pasta', 'peanut butter', 'peanut butter sandwich', 'pepper', 'pepsi', 'pierogies', 'pizza', 'pizza chocolate chip', 'pizza cooky steak', 'plantain chip', 'pop', 'popcorn', 'pot pie', 'potato', 'potato chip', 'potato soup', 'pretzals', 'pretzel', 'protein bar', 'quinoa', 'ranch', 'reese', 'rice', 'ritz', 'salsa', 'salt', 'salty snack', 'slim jims', 'snack', 'soda', 'soup', 'spaghetti', 'sponge candy', 'squash', 'sub', 'sushi', 'sweet', 'terra chip', 'tikka masala', 'toast', 'tomato soup', 'truffle', 'tuna sandwich', 'twizzlers', 'vinegar chip', 'watermelon', 'wine', 'wing', 'yogurt']\n"
     ]
    }
   ],
   "source": [
    "comfort_food_col1 = []\n",
    "comfort_food_col2 = []\n",
    "\n",
    "\n",
    "for x in range(len(data_nlp[\"comfort_food\"])):\n",
    "    a = chunk_NP(data_nlp.loc[x,'comfort_food'])\n",
    "    comfort_food_col1.append(a)\n",
    "\n",
    "    b = chunk_NP(data_nlp.loc[x, 'comfort_food_reasons'])\n",
    "    comfort_food_col2.append(b)\n",
    "\n",
    "flat_list_1st = [item for sublist in comfort_food_col1 for item in sublist]\n",
    "\n",
    "print(sorted(set(flat_list_1st))) #TODO check the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the results from the unique value from comfort_food:\n",
    "\n",
    "['/', 'almond', 'any kind', 'banana sandwich', 'beef jerky', 'bread', 'bread/crackers', 'broccoli', 'brownie', 'burger', 'burrito', 'butter', 'butter naan', 'cake', 'candy', 'candy bar', 'candy pop chocolate chipotle moe', 'carrot', 'cereal', 'cheese', 'cheeseburger', 'cheesecake', 'cheez-its', 'chex-mix', 'chicken', 'chicken curry', 'chicken finger', 'chicken nugget', 'chicken nuggs', 'chicken wing', 'chilli', 'chip', 'chocolate', 'chocolate bar', 'chocolate brownie', 'chocolate ice cream', 'coffee', 'cookie dough', 'cooky', 'cornbread', 'cottage cheese', 'cup', 'deli sandwhich', 'dessets', 'dip', 'dish', 'donut', 'doritos', 'doughnut', 'egg', 'fast food', 'fire', 'food', 'fritos', 'fruit', 'fruit snack', 'fry', 'grandma', 'grandma homemade chocolate cake anything homemade', 'grape', 'hamburger', 'home', 'ice capps', 'ice crea', 'ice cream', 'ice cream/milkshake', 'ice-cream', 'icecream', 'kit kat', 'lasagna', 'lasagne', 'mac', 'macaroni', 'macaroon', 'mcdonalds', 'meatball sub', 'milkshake', 'mix', 'moes', 'mozzarella stick', 'nan', 'none', 'noodle', 'nugget', 'nutella', 'omelet', 'pasta', 'peanut butter', 'peanut butter sandwich', 'pepper', 'pepsi', 'pierogies', 'pizza', 'pizza chocolate chip', 'pizza cooky steak', 'plantain chip', 'pop', 'popcorn', 'pot pie', 'potato', 'potato chip', 'potato soup', 'pretzals', 'pretzel', 'protein bar', 'quinoa', 'ranch', 'reese', 'rice', 'ritz', 'salsa', 'salt', 'salty snack', 'slim jims', 'snack', 'soda', 'soup', 'spaghetti', 'sponge candy', 'squash', 'sub', 'sushi', 'sweet', 'terra chip', 'tikka masala', 'toast', 'tomato soup', 'truffle', 'tuna sandwich', 'twizzlers', 'vinegar chip', 'watermelon', 'wine', 'wing', 'yogurt']\n",
    "\n",
    "\n",
    "\n",
    "#### I manually removed certain words from the list that were not appropriate for describing food.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home', 'donut', 'pop', 'chilli', 'lasagne', '/', 'pretzals', 'ice cream/milkshake', 'ice crea', 'mix', 'dessets', 'sweet', 'any kind', 'dish', 'food', 'fire', 'ice-cream', 'bread/crackers', 'cup', 'candy pop chocolate chipotle moe', 'nan', 'salt', 'icecream', 'dip', 'mac', 'chicken nuggs', 'grandma', 'grandma homemade chocolate cake anything homemade']\n"
     ]
    }
   ],
   "source": [
    "list_keep_1st = ['almond', 'banana sandwich', 'beef jerky', 'bread',  'broccoli', 'brownie', 'burger', 'burrito', 'butter', 'butter naan', 'cake', 'candy', 'candy bar','carrot', 'cereal', 'cheese', 'cheeseburger', 'cheesecake', 'cheez-its', 'chex-mix', 'chicken', 'chicken curry', 'chicken finger', 'chicken nugget', 'chicken wing',  'chip', 'chocolate', 'chocolate bar', 'chocolate brownie', 'chocolate ice cream', 'coffee', 'cookie dough', 'cooky', 'cornbread', 'cottage cheese', 'deli sandwhich', 'doritos', 'doughnut', 'egg', 'fast food', 'fritos', 'fruit', 'fruit snack', 'fry', 'grape', 'hamburger', 'ice capps', 'ice cream', 'kit kat', 'lasagna', 'macaroni', 'macaroon', 'mcdonalds', 'meatball sub', 'milkshake', 'moes', 'mozzarella stick', 'none', 'noodle', 'nugget', 'nutella', 'omelet', 'pasta', 'peanut butter', 'peanut butter sandwich', 'pepper', 'pepsi', 'pierogies', 'pizza', 'pizza chocolate chip', 'pizza cooky steak', 'plantain chip', 'popcorn', 'pot pie', 'potato', 'potato chip', 'potato soup', 'pretzel', 'protein bar', 'quinoa', 'ranch', 'reese', 'rice', 'ritz', 'salsa', 'salty snack', 'slim jims', 'snack', 'soda', 'soup', 'spaghetti', 'sponge candy', 'squash', 'sub', 'sushi', 'terra chip', 'tikka masala', 'toast', 'tomato soup', 'truffle', 'tuna sandwich', 'twizzlers', 'vinegar chip', 'watermelon', 'wine', 'wing', 'yogurt']\n",
    "\n",
    "\n",
    "list_remove_1st = list(set(flat_list_1st)-set(list_keep_1st))\n",
    "print(list_remove_1st) ##TODO Check what words werer sorted out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences_with_word(sentences, target_words):\n",
    "    matched_sentences = []\n",
    "    count =0\n",
    "    for target_word in target_words:\n",
    "        pattern = r'\\b{}\\b'.format(re.escape(target_word))\n",
    "        matched_sentence = [sentence for sentence in sentences if re.search(pattern, sentence, re.IGNORECASE)]\n",
    "        matched_sentences.append(matched_sentence)\n",
    "        count = count+1\n",
    "        print(target_word, matched_sentence, \": \\n\")\n",
    "    return matched_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def find_sentences_with_word(sentences, target_words, threshold=0.85):\n",
    "    matched_sentences = []\n",
    "    \n",
    "    for target_word in target_words:\n",
    "        matched_sentence = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = re.findall(r'\\w+', sentence.lower())\n",
    "            \n",
    "            for word in words:\n",
    "                similarity = difflib.SequenceMatcher(None, word, target_word).ratio()\n",
    "                \n",
    "                if similarity >= threshold:\n",
    "                    matched_sentence.append(sentence)\n",
    "                    break  # No need to check further words in the same sentence\n",
    "                \n",
    "        matched_sentences.append(matched_sentence)\n",
    "        print(target_word, matched_sentence, \": \\n\")\n",
    "\n",
    "    return matched_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moe's le  \n",
      "noodle ( any kinds of noodle), tuna sandwich, and egg.\n"
     ]
    }
   ],
   "source": [
    "print(data_nlp.loc[39, 'comfort_food'])\n",
    "print(data_nlp.loc[117, 'comfort_food'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candy pop chocolate chipotle moe's \n"
     ]
    }
   ],
   "source": [
    "old_value = \"candy\\rpop\\rchocolate \\rchipotle \\rmoe's \"\n",
    "new_value = \"candy pop chocolate chipotle moe's \"\n",
    "\n",
    "data_nlp['comfort_food'] = data_nlp['comfort_food'].replace(old_value, new_value)\n",
    "\n",
    "print(data_nlp.loc[39, 'comfort_food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home [\"grandma's chinese, peruvian food from back home, and sushi\"] : \n",
      "\n",
      "donut ['donuts, ice cream, chips', 'cookies, donuts, candy bars', 'little debbie snacks, donuts, pizza'] : \n",
      "\n",
      "pop [\"candy pop chocolate chipotle moe's \", 'ice cream, cake, pop, pizza, and milkshakes.'] : \n",
      "\n",
      "chilli ['chilli, soup, pot pie'] : \n",
      "\n",
      "lasagne ['chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'mac n cheese, lasagna, pizza'] : \n",
      "\n",
      "/ [] : \n",
      "\n",
      "pretzals ['chocolate, ice cream, french fries, pretzels', 'peanut butter sandwich, pretzals, garlic bread', 'peanut butter, dessets, pretzels. ', 'carrots and ranch, pretzels, dark chocolate ', 'pizza, pretzels, fruit snacks, deli sandwhich', 'chocolate bar, ice cream, pretzels, potato chips and protein bars.'] : \n",
      "\n",
      "ice cream/milkshake [] : \n",
      "\n",
      "ice crea ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "mix ['chex-mix, wegmans cookies, cheez-its ', 'popcorn, chex mix, pizza'] : \n",
      "\n",
      "dessets ['peanut butter, dessets, pretzels. '] : \n",
      "\n",
      "sweet ['chocolate, sweets, ice cream', 'chips sweets popcorn'] : \n",
      "\n",
      "any kind [] : \n",
      "\n",
      "dish [] : \n",
      "\n",
      "food ['frozen yogurt, pizza, fast food', 'fast food, pizza, subs', 'chips, ice cream, microwaveable foods ', \"grandma's chinese, peruvian food from back home, and sushi\", 'ice cream, cookies,  chinese food, and chicken nuggets ', 'chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'ice cream, pizza, chinese food ', 'burgers, indian and korean food\\r'] : \n",
      "\n",
      "fire ['chocolate, chips, ice cream, french fires, pizza'] : \n",
      "\n",
      "ice-cream ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "bread/crackers [] : \n",
      "\n",
      "cup [\"dark chocolate, terra chips, reese's cups(dark chocolate), and bread/crackers with cottage cheese\"] : \n",
      "\n",
      "candy pop chocolate chipotle moe [] : \n",
      "\n",
      "nan ['nan', 'pizza, soda, chocolate brownie, chicken tikka masala and butter naan '] : \n",
      "\n",
      "salt ['ice cream, cereal, and salt and vinegar chips ', 'candy, salty snacks, toast'] : \n",
      "\n",
      "icecream ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "dip ['chips and dip, pepsi, ', 'chips, dip, fries, pizza'] : \n",
      "\n",
      "mac ['pizza, mac and cheese, ice cream', 'mac and cheese, chocolate, and pasta ', 'cookies, mac-n-cheese, brownies, french fries, ', 'mac n cheese, peanut butter and banana sandwich, omelet', 'mac and cheese, fried chicken, cornbread ', 'fried chicken. mashed potatoes, mac and cheese', 'mac n cheese. chips and salsa. ice cream. ', 'mac and cheese', 'chips, mac and cheese, pizza, french fries ', 'mac and cheese, potato soup, ice cream, chips and cheese', 'pizza, pasta, mac and cheese', 'mac and cheese, lasagna, chinese food ', 'doritos, mac and cheese, ice cream', 'mac and cheese, pizza, ice cream and french fries ', 'mac & cheese, frosted brownies, chicken nuggs', 'mac in cheese, pizza, mozzarella sticks ', 'wine. mac and cheese, pizza, ice cream ', 'mac n cheese, lasagna, pizza'] : \n",
      "\n",
      "chicken nuggs [] : \n",
      "\n",
      "grandma ['pasta, grandma homemade chocolate cake anything homemade ', \"grandma's chinese, peruvian food from back home, and sushi\"] : \n",
      "\n",
      "grandma homemade chocolate cake anything homemade [] : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avadacadabra = find_sentences_with_word(data_nlp['comfort_food'], list_remove_1st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's list of problem of unconsistant string format:\n",
    "\n",
    "1. no comma between items\n",
    "2. sepeated by slas or dash instead of comma\n",
    "3. wrong spelling\n",
    "4. too broad name (such as food, salt)\n",
    "5. name with mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chinese food, korean food \n",
    "mac and cheese vs mac n cheese\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Modification after 1st output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check list:\n",
    "\n",
    "1. no comma between items\n",
    "2. sepeated by slas or dash instead of comma -> done using regular expression\n",
    "3. wrong spelling\n",
    "4. too broad name (such as food, salt)\n",
    "5. name with mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tree(text):\n",
    "    grammar =  r'''\n",
    "    NP: {<custom_tags_foodtypes><NN>|<RB>?<NN.*>+|<NN><CC><NN>|<DT>?<NN|NNS>+<POS>?}\n",
    "    '''\n",
    "\n",
    "    custom_tags_foodtypes = ['chinese', 'korean']\n",
    "    custom_tags_waste = ['grandma', 'homemade']\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    ## FT stand for food type\n",
    "    lotr_pos_tags = [\n",
    "        (word, custom_tags_foodtypes) if word in custom_tags_foodtypes\n",
    "    else (word, tag) for word, tag in nltk.pos_tag(tokens)]\n",
    "                 \n",
    "    # lotr_pos_tags = nltk.pos_tag(tokens) ## previous version\n",
    "\n",
    "\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "    tree = chunk_parser.parse(lotr_pos_tags)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is an additional function I developed to sanitize informal language. Given my expertise, I couldn't come up with a more suitable alternative.'''\n",
    "\n",
    "def informal2formal(text):\n",
    "\n",
    "    text = remove_nonaplpha(text)\n",
    "    formal_tokens = []\n",
    "    informal_to_formal = {\n",
    "\n",
    "        \"n\" : \"and\",  \n",
    "        \"crea\" : \"cream\", # typo\n",
    "        'egg.' : \"egg\", # typo\n",
    "        'fire' : 'fry',\n",
    "        'icecream' : 'ice cream'\n",
    "        # \"\\r\" : \",\" # input format : multiline cell\n",
    "    }\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    for token in tokens:\n",
    "        if informal_to_formal.get(token) is not None:\n",
    "            formal_tokens.append(informal_to_formal.get(token))\n",
    "        else:\n",
    "            formal_tokens.append(token)\n",
    "    \n",
    "    ## convert plural to singular\n",
    "    formal_tokens = [lemmatizer.lemmatize(word)for word in formal_tokens]\n",
    "\n",
    "    return formal_tokens\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_nonaplpha(text):\n",
    "    # Remove any non-alphabetic characters except for hyphens and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s\\,\\/-]', ' ', text)\n",
    "    # Replace multiple spaces or hyphens with a single space\n",
    "    text = re.sub(r'[\\s]+', ' ', text)\n",
    "    # Replace hyphens with a space\n",
    "    text = text.replace('-', ' ')\n",
    "    ## Replace foward slash with a comma\n",
    "    text = text.replace('/', ', ')\n",
    "    # Trim leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This is main function that chunk the sentence into word with POS tag using parser. It will also create tree that shows structure of sentence '''\n",
    "def chunk_NP(text):\n",
    "    grammar =  r'''\n",
    "    NP: { <RB>?<NN>*|<NN><CC><NN>|<DT>?<JJ>*<NN|NNS>+|}\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    The rule states that whenever the chunk finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN) then the Noun Phrase(NP) chunk should be formed.\n",
    "    '''\n",
    "\n",
    "\n",
    "    if type(text) is not str:\n",
    "        return ['none']\n",
    "    else:    \n",
    "        text = informal2formal(text)\n",
    "            \n",
    "        lotr_pos_tags = nltk.pos_tag(text)\n",
    "        chunk_parser = nltk.RegexpParser(grammar)\n",
    "        tree = chunk_parser.parse(lotr_pos_tags)\n",
    "\n",
    "        noun_phrases = []\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() =='NP':\n",
    "                np_parts = []\n",
    "                for leaf in subtree.leaves():\n",
    "                    np_parts.append(leaf[0])\n",
    "                noun_phrases.append(\" \".join(np_parts))\n",
    "        return noun_phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'little debbie snack', 'mac cheese', 'chex mix', 'slim', 'microwaveable food', 'peruvian food', 'dessets', 'sweet', 'french fry', 'korean food', 'nan', 'hot chocolate', 'wegmans', 'donut', 'frozen yogurt', 'sweet popcorn', 'lasagne', 'jims', 'pretzals', 'reese s cup dark chocolate', 'salt', 'noodle soup', 'pasta dish', 'pop', 'cracker', 'stuffed pepper', 'grandma s', 'cheese chip', 'chinese food', 'dip', 'wine mac', 'dark chocolate', 'grandma homemade chocolate cake anything homemade', 'back home', 'spaghetti squash', 'chilli', 'salsa ice cream', 'bagel ice capps', 'garlic bread', 'any kind', 'candy pop chocolate chipotle moe s', 'nuggs', 'french fire', 'mac'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "comfort_food_col1 = []\n",
    "comfort_food_col2 = []\n",
    "\n",
    "\n",
    "for x in range(len(data_nlp[\"comfort_food\"])):\n",
    "    a = chunk_NP(data_nlp.loc[x,'comfort_food'])\n",
    "    comfort_food_col1.append(a)\n",
    "\n",
    "    b = chunk_NP(data_nlp.loc[x, 'comfort_food_reasons'])\n",
    "    comfort_food_col2.append(b)\n",
    "\n",
    "flat_list_2nd = [item for sublist in comfort_food_col1 for item in sublist]\n",
    "\n",
    "# print(set(flat_list_2nd)) #TODO check the output\n",
    "\n",
    "\n",
    "list_remove_2nd = set(flat_list_2nd).difference(list_keep_1st)\n",
    "print(list_remove_2nd) ##TODO Check what words werer sorted out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'back home', 'spaghetti squash', 'frozen yogurt', 'sweet popcorn', 'little debbie snack', 'mac cheese', 'chex mix', 'salsa ice cream', 'slim', 'microwaveable food', 'jims', 'cracker', 'bagel ice capps', 'stuffed pepper', 'peruvian food', 'garlic bread', 'reese s cup dark chocolate', 'grandma s', 'candy pop chocolate chipotle moe s', 'nuggs', 'cheese chip', 'french fire', 'french fry', 'korean food', 'chinese food', 'noodle soup', 'wine mac', 'dark chocolate', 'hot chocolate', 'pasta dish', 'wegmans'}\n"
     ]
    }
   ],
   "source": [
    "# print(set(flat_list_2nd).difference(set(flat_list_1st)))\n",
    "print(set(flat_list_2nd)-set(flat_list_1st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none']\n",
      "['chocolate', 'chip', 'ice cream']\n",
      "['frozen yogurt', 'pizza', 'fast food']\n",
      "['pizza', 'mac', 'cheese', 'ice cream']\n",
      "['ice cream', 'chocolate', 'chip']\n",
      "['candy', 'brownie', 'soda']\n",
      "['chocolate', 'ice cream', 'french fry', 'pretzel']\n",
      "['ice cream', 'cheeseburger', 'chip']\n",
      "['donut', 'ice cream', 'chip']\n",
      "['mac', 'cheese', 'chocolate', 'pasta']\n",
      "['pasta', 'grandma homemade chocolate cake anything homemade']\n",
      "['chocolate', 'pasta', 'soup', 'chip', 'popcorn']\n",
      "['cooky', 'popcorn', 'chip']\n",
      "['ice cream', 'cake', 'chocolate']\n",
      "['pizza', 'fruit', 'spaghetti', 'chicken', 'potato']\n",
      "['cooky', 'donut', 'candy bar']\n",
      "['candy', 'kit kat']\n",
      "['chip', 'cooky', 'ice cream']\n",
      "['chocolate', 'ice cream']\n",
      "['pizza', 'wing']\n",
      "['fast food', 'pizza', 'sub']\n",
      "['chocolate', 'sweet', 'ice cream']\n",
      "['burger', 'chip', 'cooky']\n",
      "['chilli', 'soup', 'pot pie']\n",
      "['soup', 'pasta', 'brownie']\n",
      "['chocolate', 'ice cream', 'milkshake', 'cooky']\n",
      "['chip', 'ice cream', 'microwaveable food']\n",
      "['chicken finger', 'pizza']\n",
      "['cooky', 'hot chocolate', 'beef jerky']\n",
      "['tomato soup', 'pizza', 'fritos', 'meatball sub', 'pepper']\n",
      "['cooky', 'mac', 'cheese', 'brownie', 'french fry']\n",
      "['chip', 'dip', 'pepsi']\n",
      "['grandma s', 'peruvian food', 'back home', 'sushi']\n",
      "['ice cream', 'cooky', 'chinese food', 'nugget']\n",
      "['french fry', 'chip', 'ice cream']\n",
      "['mac', 'cheese', 'peanut butter', 'banana sandwich', 'omelet']\n",
      "['pizza', 'doughnut', 'mcdonalds']\n",
      "['chocolate', 'chip', 'candy']\n",
      "['chocolate', 'popcorn', 'ice cream']\n",
      "['candy pop chocolate chipotle moe s']\n",
      "['pizza', 'ice cream', 'fry', 'cereal', 'cooky']\n",
      "['ice cream', 'chocolate', 'twizzlers']\n",
      "['ice cream', 'cookie dough', 'cooky', 'cheese']\n",
      "['ice cream', 'cereal', 'salt', 'vinegar chip']\n",
      "['potato chip', 'ice cream', 'chocolate', 'cooky']\n",
      "['mac', 'cheese', 'chicken', 'cornbread']\n",
      "['popcorn', 'chip', 'candy', 'fry']\n",
      "['chex mix', 'wegmans']\n",
      "['pizza', 'ice cream', 'chip']\n",
      "['chicken', 'potato', 'mac', 'cheese']\n",
      "['popcorn', 'chex mix', 'pizza']\n",
      "['burger']\n",
      "['pizza', 'chocolate', 'ice cream']\n",
      "['fry', 'chip', 'chicken', 'pizza', 'grape']\n",
      "['peanut butter sandwich', 'pretzals', 'garlic bread']\n",
      "['chip', 'dip', 'fry', 'pizza']\n",
      "['pizza', 'ice cream', 'chicken wing']\n",
      "['pizza chocolate chip', 'bagel ice capps']\n",
      "['chocolate', 'ice cream', 'pasta']\n",
      "['mac', 'cheese chip', 'salsa ice cream']\n",
      "['peanut butter', 'dessets', 'pretzel']\n",
      "['macaroon', 'truffle', 'peanut butter', 'chocolate ice cream']\n",
      "['ice cream', 'cooky', 'ice cream']\n",
      "['carrot', 'ranch', 'pretzel', 'dark chocolate']\n",
      "['cooky', 'nutella', 'ice cream', 'coffee', 'fruit']\n",
      "['mac', 'cheese']\n",
      "['chocolate', 'popcorn', 'ice cream']\n",
      "['ice cream', 'cake', 'mozzarella stick', 'pierogies']\n",
      "['chip', 'mac', 'cheese', 'pizza', 'french fry']\n",
      "['pizza', 'burrito', 'slim', 'jims']\n",
      "['broccoli', 'spaghetti squash', 'quinoa', 'chicken']\n",
      "['chocolate', 'ice cream', 'cookie dough']\n",
      "['pizza', 'pretzel', 'fruit snack', 'deli sandwhich']\n",
      "['chip', 'ice cream']\n",
      "['nan']\n",
      "['mac', 'cheese', 'potato soup', 'ice cream', 'chip', 'cheese']\n",
      "['chocolate', 'pizza', 'potato']\n",
      "['pizza cooky steak']\n",
      "['chocolate', 'fruit', 'ice cream']\n",
      "['chip', 'sweet popcorn']\n",
      "['cooky', 'burger', 'noodle soup', 'ice cream']\n",
      "['cake', 'french fry', 'chicken nugget']\n",
      "['pizza', 'ice cream', 'cooky']\n",
      "['potato', 'pasta']\n",
      "['pasta dish', 'cheesecake']\n",
      "['ice cream', 'pizza', 'cooky']\n",
      "['chinese food', 'moes', 'sponge candy', 'lasagne']\n",
      "['pizza', 'pasta', 'mac', 'cheese']\n",
      "['little debbie snack', 'donut', 'pizza']\n",
      "['carrot', 'plantain chip', 'almond', 'popcorn']\n",
      "['chip', 'ice cream', 'fruit snack']\n",
      "['macaroni', 'cheese', 'noodle soup', 'pizza']\n",
      "['chocolate', 'chip', 'ice cream', 'french fire', 'pizza']\n",
      "['mac', 'cheese', 'lasagna', 'chinese food']\n",
      "['candy', 'mcdonalds']\n",
      "['doritos', 'mac', 'cheese', 'ice cream']\n",
      "['ice cream', 'cake', 'pop', 'pizza']\n",
      "['mac', 'cheese', 'pizza', 'ice cream', 'french fry']\n",
      "['soup', 'pasta']\n",
      "['mac cheese', 'brownie', 'chicken', 'nuggs']\n",
      "['watermelon', 'grape', 'ice cream']\n",
      "['macaroni', 'cheese', 'stuffed pepper', 'hamburger', 'french fry']\n",
      "['pizza', 'potato', 'spaghetti']\n",
      "['dark chocolate', 'terra chip', 'reese s cup dark chocolate', 'bread', 'cracker', 'cottage cheese']\n",
      "['chip', 'chocolate', 'mozzarella stick']\n",
      "['ice cream', 'chip', 'candy']\n",
      "['pizza', 'soda', 'chocolate brownie', 'tikka masala', 'butter naan']\n",
      "['chocolate', 'pasta', 'cooky']\n",
      "['candy', 'salty snack', 'toast']\n",
      "['mac', 'cheese', 'pizza', 'mozzarella stick']\n",
      "['ice cream', 'pizza', 'chocolate']\n",
      "['snack', 'chip']\n",
      "['chocolate', 'ice cream', 'pizza']\n",
      "['ice cream', 'pizza', 'chinese food']\n",
      "['burger', 'korean food']\n",
      "['chocolate bar', 'ice cream', 'pretzel', 'potato chip', 'protein bar']\n",
      "['ice cream', 'chocolate', 'pizza']\n",
      "['any kind', 'noodle', 'tuna sandwich', 'egg']\n",
      "['chip', 'cake']\n",
      "['chip', 'rice', 'chicken curry']\n",
      "['wine mac', 'cheese', 'pizza', 'ice cream']\n",
      "['pizza', 'wing']\n",
      "['rice', 'potato', 'soup']\n",
      "['mac', 'cheese', 'lasagna', 'pizza']\n",
      "['chocolate', 'pizza', 'ritz']\n"
     ]
    }
   ],
   "source": [
    "for x in comfort_food_col1:\n",
    "    print(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home [\"grandma's chinese, peruvian food from back home, and sushi\"] : \n",
      "\n",
      "donut ['donuts, ice cream, chips', 'cookies, donuts, candy bars', 'little debbie snacks, donuts, pizza'] : \n",
      "\n",
      "pop [\"candy pop chocolate chipotle moe's \", 'ice cream, cake, pop, pizza, and milkshakes.'] : \n",
      "\n",
      "chilli ['chilli, soup, pot pie'] : \n",
      "\n",
      "lasagne ['chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'mac n cheese, lasagna, pizza'] : \n",
      "\n",
      "/ [] : \n",
      "\n",
      "pretzals ['chocolate, ice cream, french fries, pretzels', 'peanut butter sandwich, pretzals, garlic bread', 'peanut butter, dessets, pretzels. ', 'carrots and ranch, pretzels, dark chocolate ', 'pizza, pretzels, fruit snacks, deli sandwhich', 'chocolate bar, ice cream, pretzels, potato chips and protein bars.'] : \n",
      "\n",
      "ice cream/milkshake [] : \n",
      "\n",
      "ice crea ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "mix ['chex-mix, wegmans cookies, cheez-its ', 'popcorn, chex mix, pizza'] : \n",
      "\n",
      "dessets ['peanut butter, dessets, pretzels. '] : \n",
      "\n",
      "sweet ['chocolate, sweets, ice cream', 'chips sweets popcorn'] : \n",
      "\n",
      "any kind [] : \n",
      "\n",
      "dish [] : \n",
      "\n",
      "food ['frozen yogurt, pizza, fast food', 'fast food, pizza, subs', 'chips, ice cream, microwaveable foods ', \"grandma's chinese, peruvian food from back home, and sushi\", 'ice cream, cookies,  chinese food, and chicken nuggets ', 'chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'ice cream, pizza, chinese food ', 'burgers, indian and korean food\\r'] : \n",
      "\n",
      "fire ['chocolate, chips, ice cream, french fires, pizza'] : \n",
      "\n",
      "ice-cream ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "bread/crackers [] : \n",
      "\n",
      "cup [\"dark chocolate, terra chips, reese's cups(dark chocolate), and bread/crackers with cottage cheese\"] : \n",
      "\n",
      "candy pop chocolate chipotle moe [] : \n",
      "\n",
      "nan ['nan', 'pizza, soda, chocolate brownie, chicken tikka masala and butter naan '] : \n",
      "\n",
      "salt ['ice cream, cereal, and salt and vinegar chips ', 'candy, salty snacks, toast'] : \n",
      "\n",
      "icecream ['chocolate, popcorn, icecream'] : \n",
      "\n",
      "dip ['chips and dip, pepsi, ', 'chips, dip, fries, pizza'] : \n",
      "\n",
      "mac ['pizza, mac and cheese, ice cream', 'mac and cheese, chocolate, and pasta ', 'cookies, mac-n-cheese, brownies, french fries, ', 'mac n cheese, peanut butter and banana sandwich, omelet', 'mac and cheese, fried chicken, cornbread ', 'fried chicken. mashed potatoes, mac and cheese', 'mac n cheese. chips and salsa. ice cream. ', 'mac and cheese', 'chips, mac and cheese, pizza, french fries ', 'mac and cheese, potato soup, ice cream, chips and cheese', 'pizza, pasta, mac and cheese', 'mac and cheese, lasagna, chinese food ', 'doritos, mac and cheese, ice cream', 'mac and cheese, pizza, ice cream and french fries ', 'mac & cheese, frosted brownies, chicken nuggs', 'mac in cheese, pizza, mozzarella sticks ', 'wine. mac and cheese, pizza, ice cream ', 'mac n cheese, lasagna, pizza'] : \n",
      "\n",
      "chicken nuggs [] : \n",
      "\n",
      "grandma ['pasta, grandma homemade chocolate cake anything homemade ', \"grandma's chinese, peruvian food from back home, and sushi\"] : \n",
      "\n",
      "grandma homemade chocolate cake anything homemade [] : \n",
      "\n",
      "[\"grandma's chinese, peruvian food from back home, and sushi\"] 1\n",
      "['donuts, ice cream, chips', 'cookies, donuts, candy bars', 'little debbie snacks, donuts, pizza'] 2\n",
      "[\"candy pop chocolate chipotle moe's \", 'ice cream, cake, pop, pizza, and milkshakes.'] 3\n",
      "['chilli, soup, pot pie'] 4\n",
      "['chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'mac n cheese, lasagna, pizza'] 5\n",
      "[] 6\n",
      "['chocolate, ice cream, french fries, pretzels', 'peanut butter sandwich, pretzals, garlic bread', 'peanut butter, dessets, pretzels. ', 'carrots and ranch, pretzels, dark chocolate ', 'pizza, pretzels, fruit snacks, deli sandwhich', 'chocolate bar, ice cream, pretzels, potato chips and protein bars.'] 7\n",
      "[] 8\n",
      "['chocolate, popcorn, icecream'] 9\n",
      "['chex-mix, wegmans cookies, cheez-its ', 'popcorn, chex mix, pizza'] 10\n",
      "['peanut butter, dessets, pretzels. '] 11\n",
      "['chocolate, sweets, ice cream', 'chips sweets popcorn'] 12\n",
      "[] 13\n",
      "[] 14\n",
      "['frozen yogurt, pizza, fast food', 'fast food, pizza, subs', 'chips, ice cream, microwaveable foods ', \"grandma's chinese, peruvian food from back home, and sushi\", 'ice cream, cookies,  chinese food, and chicken nuggets ', 'chinese food, moes, sponge candy, homemade lasagne ', 'mac and cheese, lasagna, chinese food ', 'ice cream, pizza, chinese food ', 'burgers, indian and korean food\\r'] 15\n",
      "['chocolate, chips, ice cream, french fires, pizza'] 16\n",
      "['chocolate, popcorn, icecream'] 17\n",
      "[] 18\n",
      "[\"dark chocolate, terra chips, reese's cups(dark chocolate), and bread/crackers with cottage cheese\"] 19\n",
      "[] 20\n",
      "['nan', 'pizza, soda, chocolate brownie, chicken tikka masala and butter naan '] 21\n",
      "['ice cream, cereal, and salt and vinegar chips ', 'candy, salty snacks, toast'] 22\n",
      "['chocolate, popcorn, icecream'] 23\n",
      "['chips and dip, pepsi, ', 'chips, dip, fries, pizza'] 24\n",
      "['pizza, mac and cheese, ice cream', 'mac and cheese, chocolate, and pasta ', 'cookies, mac-n-cheese, brownies, french fries, ', 'mac n cheese, peanut butter and banana sandwich, omelet', 'mac and cheese, fried chicken, cornbread ', 'fried chicken. mashed potatoes, mac and cheese', 'mac n cheese. chips and salsa. ice cream. ', 'mac and cheese', 'chips, mac and cheese, pizza, french fries ', 'mac and cheese, potato soup, ice cream, chips and cheese', 'pizza, pasta, mac and cheese', 'mac and cheese, lasagna, chinese food ', 'doritos, mac and cheese, ice cream', 'mac and cheese, pizza, ice cream and french fries ', 'mac & cheese, frosted brownies, chicken nuggs', 'mac in cheese, pizza, mozzarella sticks ', 'wine. mac and cheese, pizza, ice cream ', 'mac n cheese, lasagna, pizza'] 25\n",
      "[] 26\n",
      "['pasta, grandma homemade chocolate cake anything homemade ', \"grandma's chinese, peruvian food from back home, and sushi\"] 27\n",
      "[] 28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avadacadabra = find_sentences_with_word(data_nlp['comfort_food'], list_remove_1st)\n",
    "\n",
    "count =0\n",
    "for x in avadacadabra:\n",
    "    count = count+1\n",
    "    print(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning.loc[:,['comfort_food','comfort_food_reasons', 'diet_current']] = data_nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none' 'chocolate, chips, ice cream' 'frozen yogurt, pizza, fast food'\n",
      " 'pizza, mac and cheese, ice cream' 'ice cream, chocolate, chips '\n",
      " 'candy, brownies and soda.'\n",
      " 'chocolate, ice cream, french fries, pretzels'\n",
      " 'ice cream, cheeseburgers, chips.' 'donuts, ice cream, chips'\n",
      " 'mac and cheese, chocolate, and pasta '\n",
      " 'pasta, grandma homemade chocolate cake anything homemade '\n",
      " 'chocolate, pasta, soup, chips, popcorn' 'cookies, popcorn, and chips'\n",
      " 'ice cream, cake, chocolate'\n",
      " 'pizza, fruit, spaghetti, chicken and potatoes  '\n",
      " 'cookies, donuts, candy bars' 'saltfish, candy and kit kat '\n",
      " 'chips, cookies, ice cream' 'chocolate, ice crea '\n",
      " 'pizza, wings, chinese' 'fast food, pizza, subs'\n",
      " 'chocolate, sweets, ice cream' 'burgers, chips, cookies'\n",
      " 'chilli, soup, pot pie' 'soup, pasta, brownies, cake'\n",
      " 'chocolate, ice cream/milkshake, cookies'\n",
      " 'chips, ice cream, microwaveable foods ' 'chicken fingers, pizza '\n",
      " 'cookies, hot chocolate, beef jerky'\n",
      " 'tomato soup, pizza, fritos, meatball sub, dr. pepper'\n",
      " 'cookies, mac-n-cheese, brownies, french fries, '\n",
      " 'chips and dip, pepsi, '\n",
      " \"grandma's chinese, peruvian food from back home, and sushi\"\n",
      " 'ice cream, cookies,  chinese food, and chicken nuggets '\n",
      " 'french fries, chips, ice cream'\n",
      " 'mac n cheese, peanut butter and banana sandwich, omelet'\n",
      " 'pizza, doughnuts, mcdonalds ' 'chocolate, chips, candy'\n",
      " 'chocolate, popcorn, ice cream' \"candy pop chocolate chipotle moe's \"\n",
      " 'pizza, ice cream, fries, cereal, cookies  '\n",
      " 'ice cream, chocolate, twizzlers '\n",
      " 'ice cream, cookie dough, cookies, cheese'\n",
      " 'ice cream, cereal, and salt and vinegar chips '\n",
      " 'potato chips, ice cream, chocolate, cookies'\n",
      " 'mac and cheese, fried chicken, cornbread '\n",
      " 'popcorn, chips, candy, & fries ' 'chex-mix, wegmans cookies, cheez-its '\n",
      " 'pizza, ice cream, chips'\n",
      " 'fried chicken. mashed potatoes, mac and cheese'\n",
      " 'popcorn, chex mix, pizza' 'burger' 'pizza, chocolate, and ice cream '\n",
      " 'fries, chips, fried chicken, pizza, grapes'\n",
      " 'peanut butter sandwich, pretzals, garlic bread'\n",
      " 'chips, dip, fries, pizza' 'pizza, ice cream, chicken wings'\n",
      " 'pizza chocolate chips bagels ice capps ' 'chocolate, ice cream, pasta'\n",
      " 'mac n cheese. chips and salsa. ice cream. '\n",
      " 'peanut butter, dessets, pretzels. '\n",
      " 'macaroons, truffles, peanut butter n chocolate ice cream'\n",
      " 'ice cream, cookies, ice cream'\n",
      " 'carrots and ranch, pretzels, dark chocolate '\n",
      " 'cookies, nutella, ice cream, coffee, fruit ' 'mac and cheese'\n",
      " 'chocolate, popcorn, icecream'\n",
      " 'ice cream, cake, mozzarella sticks, pierogies '\n",
      " 'chips, mac and cheese, pizza, french fries '\n",
      " 'pizza, burritos, slim jims'\n",
      " 'broccoli, spaghetti squash, quinoa, and grilled chicken'\n",
      " 'chocolate, ice cream, cookie dough'\n",
      " 'pizza, pretzels, fruit snacks, deli sandwhich' 'chips, ice cream' 'nan'\n",
      " 'mac and cheese, potato soup, ice cream, chips and cheese'\n",
      " 'chocolate, pizza, and mashed potatoes' 'pizza cookies steak '\n",
      " 'chocolate, fruit, and ice cream' 'chips sweets popcorn'\n",
      " 'cookies, burgers, chicken noodle soup, ice cream'\n",
      " 'cake, french fries, chicken nuggets' 'pizza, ice cream, cookies'\n",
      " 'mashed potatoes, pasta' 'pasta dishes, cheesecake, pancakes'\n",
      " 'ice cream, pizza, cookies'\n",
      " 'chinese food, moes, sponge candy, homemade lasagne '\n",
      " 'pizza, pasta, mac and cheese' 'little debbie snacks, donuts, pizza'\n",
      " 'carrots, plantain chips, almonds, popcorn '\n",
      " 'chips, ice cream, fruit snacks'\n",
      " 'macaroni and cheese, chicken noodle soup, pizza'\n",
      " 'chocolate, chips, ice cream, french fires, pizza'\n",
      " 'mac and cheese, lasagna, chinese food ' 'candy, chinese, mcdonalds'\n",
      " 'doritos, mac and cheese, ice cream'\n",
      " 'ice cream, cake, pop, pizza, and milkshakes.'\n",
      " 'mac and cheese, pizza, ice cream and french fries ' 'soup, pasta, cake'\n",
      " 'mac & cheese, frosted brownies, chicken nuggs'\n",
      " 'watermelon, grapes, ice cream'\n",
      " 'macaroni and cheese, stuffed peppers, hamburgers, french fries'\n",
      " 'pizza, mashed potatoes, spaghetti'\n",
      " \"dark chocolate, terra chips, reese's cups(dark chocolate), and bread/crackers with cottage cheese\"\n",
      " 'chips, chocolate, ,mozzarella sticks ' 'ice cream, chips, candy'\n",
      " 'pizza, soda, chocolate brownie, chicken tikka masala and butter naan '\n",
      " 'chocolate, pasta, cookies' 'candy, salty snacks, toast'\n",
      " 'mac in cheese, pizza, mozzarella sticks ' 'ice-cream, pizza, chocolate'\n",
      " 'snacks, chips, ' 'chocolate, ice cream, pizza'\n",
      " 'ice cream, pizza, chinese food ' 'burgers, indian and korean food\\r'\n",
      " 'chocolate bar, ice cream, pretzels, potato chips and protein bars.'\n",
      " 'ice cream, chocolate, pizza, cucumber '\n",
      " 'noodle ( any kinds of noodle), tuna sandwich, and egg.\\r'\n",
      " 'chinese, chips, cake' 'chips, rice, chicken curry,'\n",
      " 'wine. mac and cheese, pizza, ice cream ' 'pizza / wings / cheesecake'\n",
      " 'rice, potato, seaweed soup' 'mac n cheese, lasagna, pizza'\n",
      " 'chocolates, pizza, and ritz.']\n",
      "(125,)\n",
      "(125,)\n"
     ]
    }
   ],
   "source": [
    "cf_explode = data_cleaning.explode('comfort_food') \n",
    "## The explode() function is used to transform each element of a list-like to a row, replicating the index values.\n",
    "\n",
    "print(cf_explode['comfort_food'].unique())\n",
    "print(cf_explode['comfort_food'].unique().shape)\n",
    "print(cf_explode['comfort_food'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grandma homemade chocolate cake anything homemade\n",
    "ice crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pizza', ',', 'wing', ',', 'cheesecake']\n"
     ]
    }
   ],
   "source": [
    "string = \"Pizza / Wings / Cheesecake\".lower()\n",
    "\n",
    "\n",
    "string2 = \"grandma homemade chocolate cake anything homemade\".lower()\n",
    "\n",
    "string3 = \"Saltfish, Candy and Kit Kat \"\n",
    "\n",
    "string4 = \"chocolate,ice cream/milkshake,cooky\"\n",
    "# print(chunk_NP(string2))\n",
    "get_Tree(string2).draw()\n",
    "# print(nltk.word_tokenize(string2))\n",
    "print(informal2formal(string))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice cream/milkshake\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "text = \"ice cream/milkshake\"\n",
    "corrected_text = spell(text)\n",
    "\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candy pop chocolate chipotle moe's \n"
     ]
    }
   ],
   "source": [
    "print(data_nlp.loc[39,'comfort_food'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
